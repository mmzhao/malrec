TODO

PRIORITY
- scrape more/better - contacted mal/ral people
- try pycuda for performance increases
- check asymmetric svd and tune params
- try different annealing schedule (learning rate adaptation)
- online support for adding users to model
- make a website of sorts and perhaps contact mal people
- write something up

LATER
- more fully capture implicit feedback by incorporating unscored but watched anime
- learn about normalization methods (https://www.cs.purdue.edu/homes/lsi/sigir04-cf-norm.pdf)
- use k-fold cross val
- timestamp crap for future predictabiltiy
- consider other loss fns besides rmse
- multithread

STAY ON LOOKOUT FOR
- way to find more users (reddit, scraping anime reviews)
- better way to scrape lists

DONE
- scrape top X most popular anime
- scrape top X most member clubs
- scrape users from clubs
- scrape animelists from users
- store everything in JSON
- set up persistant http connections for animelist requests
- use BeautifulSoup to parse xml instead of using regex
- catch exceptions
- use requests package instead of httplib
- sleep when rate limited (429)
- try each user up to X times before giving up and recording username
- try to have multiple ip sources with proxies
- make matrices
- try dif algos (and optimize)
	- cosine similarity
	- basic svd
	- stochastic gradient descent
	- alternating least squares
	- svd++
	- asymmetric svd
- scrape reddit for mal users
- run stats for histogram of animes-per-user/users-per-anime
- graph performance for dif algs with different params
- added performance metric based on threshold allowed prediction error
- make pipeline for getting list from single user
- refactor everything - based on a base model class

BOOK PAGES
- 154 - how to use rated vs seen vs plan to watch etc



